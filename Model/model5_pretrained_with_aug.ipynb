{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55860\n",
      "55860\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "train_subject_types = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "input_images=[]\n",
    "input_labels=[]\n",
    "\n",
    "train_type = ['middlefinger']\n",
    "train_set=['set1','set2','set3','set4','set5','set6']\n",
    "\n",
    "def scan_folder(train_dataset_path,label):\n",
    "    images = []\n",
    "    labels=[]\n",
    "    complete_path=[x[0] for x in os.walk(train_dataset_path)]\n",
    "    for file_name in complete_path:\n",
    "        #print(file_name)\n",
    "        for fn in  os.listdir(file_name) :\n",
    "            # print(fn)\n",
    "            if fn.endswith(\".bmp\"):\n",
    "            # if it's a txt file, print its name (or do whatever you want)\n",
    "                # print(file_name)\n",
    "                #im = Image.open(file_name+'/'+fn)\n",
    "                im = cv2.imread(file_name+'/'+fn)\n",
    "                # im.show()\n",
    "                img_arr=cv2.resize(im,(224,224))\n",
    "                # img_arr=im \n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "                #print(im.size)\n",
    "                #print(im.filename)\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((train_dataset_path, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recursively call this method\n",
    "                scan_folder(current_path)\n",
    "    #print(images)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "for item1 in train_subject_types:\n",
    "    all_train_subjects = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down' + '/' +item1)\n",
    "    #print(all_subjects)\n",
    "    for item2 in train_type:\n",
    "        for item3 in train_set:\n",
    "            path=str('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down'  + '/' +item1 +  '/session1'+ '/' +item2 + '/'+item3+ '/3D')\n",
    "            img,label=scan_folder(path,item1)\n",
    "            input_images.extend(img)\n",
    "            input_labels.extend(label)\n",
    "            #print(input_labels)\n",
    "\n",
    "input_train_images=np.array(input_images)  \n",
    "input_train_labels=np.array(input_labels)\n",
    "print(len(input_train_images))\n",
    "print(len(input_train_labels))\n",
    "#print(input_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7980, 224, 224, 3)\n",
      "(7980,)\n",
      "7980\n",
      "7980\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "test_subject_types = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "input_images=[]\n",
    "input_labels=[]\n",
    "\n",
    "test_type = ['middlefinger']\n",
    "test_set=['set1','set2','set3','set4','set5','set6']\n",
    "\n",
    "\n",
    "def scan_folder(test_dataset_path,label):\n",
    "    images = []\n",
    "    labels=[]\n",
    "    #print(test_dataset_path)\n",
    "    complete_path=[x[0] for x in os.walk(test_dataset_path)]\n",
    "    #print(complete_path)\n",
    "    for file_name in complete_path:\n",
    "        #print(file_name)\n",
    "        for fn in  os.listdir(file_name) :\n",
    "            # print(fn)\n",
    "            if fn.endswith(\".bmp\"):\n",
    "            # if it's a txt file, print its name (or do whatever you want)\n",
    "                # print(file_name)\n",
    "                #im = Image.open(file_name+'/'+fn)\n",
    "                im = cv2.imread(file_name+'/'+fn)\n",
    "                # im.show()\n",
    "                img_arr=cv2.resize(im,(224,224))\n",
    "                #img_arr=im\n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((test_dataset_path, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recursively call this method\n",
    "                scan_folder(current_path)\n",
    "    #print(images)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "for item1 in train_subject_types:\n",
    "    #all_train_subjects = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down' + '/' +item1)\n",
    "    #print(all_train_subjects)\n",
    "    for item2 in test_type:\n",
    "        for item3 in test_set:\n",
    "            path=str('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down'  + '/' +item1 +  '/session2'+ '/' +item2 + '/'+item3+ '/3D')\n",
    "            img,label=scan_folder(path,item1)\n",
    "            input_images.extend(img)\n",
    "            input_labels.extend(label)\n",
    "            # print(input_labels)\n",
    "\n",
    "input_test_images=np.array(input_images) #,axis=0)\n",
    "input_test_labels=np.array(input_labels)\n",
    "# print(input_labels.shape)\n",
    "# input_test_labels=np.concatenate(np.array(input_labels),axis=0)\n",
    "print(input_test_images.shape)\n",
    "print(input_test_labels.shape)\n",
    "print(len(input_test_images))    \n",
    "print(len(input_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55860, 224, 224, 3)\n",
      "(55860,)\n",
      "(7980, 224, 224, 3)\n",
      "(7980,)\n"
     ]
    }
   ],
   "source": [
    "X_train = input_train_images\n",
    "Y_train = input_train_labels\n",
    "\n",
    "X_test = input_test_images\n",
    "Y_test = input_test_labels\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train/22.0\n",
    "# X_test = X_test/35.0\n",
    "\n",
    "# X_train[1,:]\n",
    "# X_test[1,:]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb= LabelEncoder()\n",
    "Y_train = lb.fit_transform(Y_train)\n",
    "Y_test = lb.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1117368/3934639393.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 11:31:40.120931: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 11:31:40.625095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 14976 MB memory:  -> device: 0, name: Quadro P5000, pci bus id: 0000:18:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 11:31:51.605915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14976 MB memory:  -> device: 0, name: Quadro P5000, pci bus id: 0000:18:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "img_height,img_width = 224,224 \n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = tf.keras.applications.NASNetMobile(weights=\"imagenet\", include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "predictions = Dense(190, activation= 'softmax')(x)\n",
    "model = tf.keras.Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 11:31:59.412004: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 8408494080 exceeds 10% of free system memory.\n",
      "2023-03-11 11:32:09.155448: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 8408494080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 11:32:38.570556: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2023-03-11 11:32:38.943120: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-11 11:32:38.948305: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873/873 [==============================] - 656s 724ms/step - loss: 1.2063 - accuracy: 0.7330\n",
      "Epoch 2/50\n",
      "873/873 [==============================] - 622s 712ms/step - loss: 0.3417 - accuracy: 0.9163\n",
      "Epoch 3/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.2639 - accuracy: 0.9326\n",
      "Epoch 4/50\n",
      "873/873 [==============================] - 598s 685ms/step - loss: 0.2247 - accuracy: 0.9415\n",
      "Epoch 5/50\n",
      "873/873 [==============================] - 597s 684ms/step - loss: 0.1966 - accuracy: 0.9486\n",
      "Epoch 6/50\n",
      "873/873 [==============================] - 597s 684ms/step - loss: 0.1781 - accuracy: 0.9533\n",
      "Epoch 7/50\n",
      "873/873 [==============================] - 597s 684ms/step - loss: 0.1565 - accuracy: 0.9584\n",
      "Epoch 8/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.1451 - accuracy: 0.9612\n",
      "Epoch 9/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.1323 - accuracy: 0.9645\n",
      "Epoch 10/50\n",
      "873/873 [==============================] - 596s 682ms/step - loss: 0.1173 - accuracy: 0.9682\n",
      "Epoch 11/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.1101 - accuracy: 0.9699\n",
      "Epoch 12/50\n",
      "873/873 [==============================] - 598s 685ms/step - loss: 0.1033 - accuracy: 0.9721\n",
      "Epoch 13/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.0966 - accuracy: 0.9728\n",
      "Epoch 14/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.0902 - accuracy: 0.9751\n",
      "Epoch 15/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.0860 - accuracy: 0.9763\n",
      "Epoch 16/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0758 - accuracy: 0.9791\n",
      "Epoch 17/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.0751 - accuracy: 0.9783\n",
      "Epoch 18/50\n",
      "873/873 [==============================] - 595s 681ms/step - loss: 0.0697 - accuracy: 0.9811\n",
      "Epoch 19/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0647 - accuracy: 0.9817\n",
      "Epoch 20/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.0668 - accuracy: 0.9818\n",
      "Epoch 21/50\n",
      "873/873 [==============================] - 596s 682ms/step - loss: 0.0599 - accuracy: 0.9833\n",
      "Epoch 22/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0617 - accuracy: 0.9826\n",
      "Epoch 23/50\n",
      "873/873 [==============================] - 594s 681ms/step - loss: 0.0515 - accuracy: 0.9853\n",
      "Epoch 24/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0582 - accuracy: 0.9841\n",
      "Epoch 25/50\n",
      "873/873 [==============================] - 596s 682ms/step - loss: 0.0519 - accuracy: 0.9859\n",
      "Epoch 26/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.0493 - accuracy: 0.9862\n",
      "Epoch 27/50\n",
      "873/873 [==============================] - 594s 680ms/step - loss: 0.0492 - accuracy: 0.9867\n",
      "Epoch 28/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.0514 - accuracy: 0.9859\n",
      "Epoch 29/50\n",
      "873/873 [==============================] - 596s 682ms/step - loss: 0.0482 - accuracy: 0.9869\n",
      "Epoch 30/50\n",
      "873/873 [==============================] - 596s 683ms/step - loss: 0.0398 - accuracy: 0.9892\n",
      "Epoch 31/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0459 - accuracy: 0.9874\n",
      "Epoch 32/50\n",
      "873/873 [==============================] - 595s 681ms/step - loss: 0.0387 - accuracy: 0.9896\n",
      "Epoch 33/50\n",
      "873/873 [==============================] - 594s 681ms/step - loss: 0.0465 - accuracy: 0.9875\n",
      "Epoch 34/50\n",
      "873/873 [==============================] - 595s 681ms/step - loss: 0.0356 - accuracy: 0.9900\n",
      "Epoch 35/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0412 - accuracy: 0.9885\n",
      "Epoch 36/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0441 - accuracy: 0.9879\n",
      "Epoch 37/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0351 - accuracy: 0.9907\n",
      "Epoch 38/50\n",
      "873/873 [==============================] - 594s 681ms/step - loss: 0.0409 - accuracy: 0.9890\n",
      "Epoch 39/50\n",
      "873/873 [==============================] - 594s 681ms/step - loss: 0.0336 - accuracy: 0.9904\n",
      "Epoch 40/50\n",
      "873/873 [==============================] - 594s 680ms/step - loss: 0.0342 - accuracy: 0.9904\n",
      "Epoch 41/50\n",
      "873/873 [==============================] - 595s 681ms/step - loss: 0.0367 - accuracy: 0.9905\n",
      "Epoch 42/50\n",
      "873/873 [==============================] - 593s 679ms/step - loss: 0.0370 - accuracy: 0.9900\n",
      "Epoch 43/50\n",
      "873/873 [==============================] - 595s 681ms/step - loss: 0.0315 - accuracy: 0.9915\n",
      "Epoch 44/50\n",
      "873/873 [==============================] - 595s 681ms/step - loss: 0.0362 - accuracy: 0.9904\n",
      "Epoch 45/50\n",
      "873/873 [==============================] - 594s 681ms/step - loss: 0.0313 - accuracy: 0.9917\n",
      "Epoch 46/50\n",
      "873/873 [==============================] - 594s 681ms/step - loss: 0.0358 - accuracy: 0.9905\n",
      "Epoch 47/50\n",
      "873/873 [==============================] - 594s 680ms/step - loss: 0.0322 - accuracy: 0.9914\n",
      "Epoch 48/50\n",
      "873/873 [==============================] - 595s 681ms/step - loss: 0.0382 - accuracy: 0.9899\n",
      "Epoch 49/50\n",
      "873/873 [==============================] - 595s 682ms/step - loss: 0.0293 - accuracy: 0.9919\n",
      "Epoch 50/50\n",
      "873/873 [==============================] - 595s 681ms/step - loss: 0.0314 - accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 19s 223ms/step - loss: 13.4008 - accuracy: 0.4386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13.400755882263184, 0.4385964870452881]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/Nasnetmobile_Aug_pre_50epochs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model/Nasnetmobile_training_history.npy', history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b2f3040836d8930dd440357ce9e4d88224c51c61d44d8fa72c07609a2b5249b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
