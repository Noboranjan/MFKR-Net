{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 13:27:41.901338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 13:27:42.541342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/cv2/../../lib64:/home/bigdata_user5/Desktop/envs/nobo/lib/\n",
      "2023-06-29 13:27:42.541410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/cv2/../../lib64:/home/bigdata_user5/Desktop/envs/nobo/lib/\n",
      "2023-06-29 13:27:42.541415: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-d456bb71-756c-5f6b-b13b-6793b90de8b7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55860\n",
      "55860\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = os.listdir('3Dfingerknuckle_with_Aug/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "train_subject_types = os.listdir('3Dfingerknuckle_with_Aug/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "input_images=[]\n",
    "input_labels=[]\n",
    "\n",
    "train_type = ['middlefinger']\n",
    "train_set=['set1','set2','set3','set4','set5','set6']\n",
    "\n",
    "def scan_folder(train_dataset_path,label):\n",
    "    images = []\n",
    "    labels=[]\n",
    "    complete_path=[x[0] for x in os.walk(train_dataset_path)]\n",
    "    for file_name in complete_path:\n",
    "        #print(file_name)\n",
    "        for fn in  os.listdir(file_name):\n",
    "            # print(fn)\n",
    "            if fn.endswith(\".bmp\"):\n",
    "            # if it's a txt file, print its name (or do whatever you want)\n",
    "                # print(file_name)\n",
    "                #im = Image.open(file_name+'/'+fn)\n",
    "                im = cv2.imread(file_name+'/'+fn)\n",
    "                # im.show()\n",
    "                img_arr=cv2.resize(im,(224,224))\n",
    "                # img_arr=im \n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "                #print(im.size)\n",
    "                #print(im.filename)\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((train_dataset_path, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recursively call this method\n",
    "                scan_folder(current_path)\n",
    "    #print(images)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "for item1 in train_subject_types:\n",
    "    all_train_subjects = os.listdir('3Dfingerknuckle_with_Aug/3D_Finger_Knuckle_Database/segmented_data_down' + '/' +item1)\n",
    "    #print(all_subjects)\n",
    "    for item2 in train_type:\n",
    "        for item3 in train_set:\n",
    "            path=str('3Dfingerknuckle_with_Aug/3D_Finger_Knuckle_Database/segmented_data_down'  + '/' +item1 +  '/session1'+ '/' +item2 + '/'+item3+ '/3D')\n",
    "            img,label=scan_folder(path,item1)\n",
    "            input_images.extend(img)\n",
    "            input_labels.extend(label)\n",
    "            #print(input_labels)\n",
    "\n",
    "input_train_images=np.array(input_images)  \n",
    "input_train_labels=np.array(input_labels)\n",
    "print(len(input_train_images))\n",
    "print(len(input_train_labels))\n",
    "#print(input_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7980, 224, 224, 3)\n",
      "(7980,)\n",
      "7980\n",
      "7980\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = os.listdir('3Dfingerknuckle_with_Aug/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "test_subject_types = os.listdir('3Dfingerknuckle_with_Aug/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "input_images=[]\n",
    "input_labels=[]\n",
    "\n",
    "test_type = ['middlefinger']\n",
    "test_set=['set1','set2','set3','set4','set5','set6']\n",
    "\n",
    "\n",
    "def scan_folder(test_dataset_path,label):\n",
    "    images = []\n",
    "    labels=[]\n",
    "    #print(test_dataset_path)\n",
    "    complete_path=[x[0] for x in os.walk(test_dataset_path)]\n",
    "    #print(complete_path)\n",
    "    for file_name in complete_path:\n",
    "        #print(file_name)\n",
    "        for fn in  os.listdir(file_name) :\n",
    "            # print(fn)\n",
    "            if fn.endswith(\".bmp\"):\n",
    "            # if it's a txt file, print its name (or do whatever you want)\n",
    "                # print(file_name)\n",
    "                #im = Image.open(file_name+'/'+fn)\n",
    "                im = cv2.imread(file_name+'/'+fn)\n",
    "                # im.show()\n",
    "                img_arr=cv2.resize(im,(224,224))\n",
    "                #img_arr=im\n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((test_dataset_path, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recursively call this method\n",
    "                scan_folder(current_path)\n",
    "    #print(images)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "for item1 in train_subject_types:\n",
    "    #all_train_subjects = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down' + '/' +item1)\n",
    "    #print(all_train_subjects)\n",
    "    for item2 in test_type:\n",
    "        for item3 in test_set:\n",
    "            path=str('3Dfingerknuckle_with_Aug/3D_Finger_Knuckle_Database/segmented_data_down'  + '/' +item1 +  '/session2'+ '/' +item2 + '/'+item3+ '/3D')\n",
    "            img,label=scan_folder(path,item1)\n",
    "            input_images.extend(img)\n",
    "            input_labels.extend(label)\n",
    "            # print(input_labels)\n",
    "\n",
    "input_test_images=np.array(input_images) #,axis=0)\n",
    "input_test_labels=np.array(input_labels)\n",
    "# print(input_labels.shape)\n",
    "# input_test_labels=np.concatenate(np.array(input_labels),axis=0)\n",
    "print(input_test_images.shape)\n",
    "print(input_test_labels.shape)\n",
    "print(len(input_test_images))    \n",
    "print(len(input_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55860, 224, 224, 3)\n",
      "(55860,)\n",
      "(7980, 224, 224, 3)\n",
      "(7980,)\n"
     ]
    }
   ],
   "source": [
    "X_train = input_train_images\n",
    "Y_train = input_train_labels\n",
    "\n",
    "X_test = input_test_images\n",
    "Y_test = input_test_labels\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train/22.0\n",
    "# X_test = X_test/35.0\n",
    "\n",
    "# X_train[1,:]\n",
    "# X_test[1,:]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb= LabelEncoder()\n",
    "Y_train = lb.fit_transform(Y_train)\n",
    "Y_test = lb.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_554860/3934639393.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 13:28:07.715067: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 13:28:08.446334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 38541 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB MIG 3g.40gb, pci bus id: 0000:c2:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 11:03:25.134578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38541 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB MIG 3g.40gb, pci bus id: 0000:c2:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 224, 224, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 224, 224, 3)  0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " efficientnetv2-b2 (Functional)  (None, 7, 7, 1408)  8769374     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " xception (Functional)          (None, 7, 7, 2048)   20861480    ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 7, 7, 3456)   0           ['efficientnetv2-b2[0][0]',      \n",
      "                                                                  'xception[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 3456)        0           ['concatenate[0][0]']            \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1769984     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 190)          97470       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,498,308\n",
      "Trainable params: 31,361,492\n",
      "Non-trainable params: 136,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras_applications.EfficientNetV2B2 import , preprocess_input as resnet_preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input as xception_preprocess_input\n",
    "from keras.layers import Concatenate, GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# create ResNet50 and Xception models\n",
    "efficientnet_model = tf.keras.applications.EfficientNetV2B2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "xception_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# create input tensor\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "# preprocess input for ResNet50 and XceptionNet\n",
    "efficientnet_processed = tf.keras.applications.efficientnet.preprocess_input(input_tensor)\n",
    "xception_processed = xception_preprocess_input(input_tensor)\n",
    "\n",
    "# extract features from both models\n",
    "efficientnet_features = efficientnet_model(efficientnet_processed)\n",
    "xception_features = xception_model(xception_processed)\n",
    "\n",
    "# concatenate features\n",
    "concatenated = Concatenate()([efficientnet_features, xception_features])\n",
    "\n",
    "# add global average pooling layer\n",
    "pooled = GlobalAveragePooling2D()(concatenated)\n",
    "\n",
    "# add fully connected layers for classification\n",
    "fc1 = Dense(512, activation='relu')(pooled)\n",
    "dropout = Dropout(0.5)(fc1)\n",
    "fc2 = Dense(190, activation='softmax')(dropout)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=input_tensor, outputs=fc2)\n",
    "\n",
    "# plot model architecture\n",
    "# plot_model(model, show_shapes=True, to_file='model.png')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_filepath = 'checkpoint/checkpoint_pv5.h5'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 11:04:26.796361: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/efficientnetv2-b2/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-05-12 11:04:31.825025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-05-12 11:04:33.238678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-12 11:04:33.476921: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f95f8012dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-12 11:04:33.476952: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB MIG 3g.40gb, Compute Capability 8.0\n",
      "2023-05-12 11:04:33.481746: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-12 11:04:33.591233: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873/873 [==============================] - 468s 462ms/step - loss: 1.1725 - accuracy: 0.7386 - val_loss: 1.6966 - val_accuracy: 0.6868\n",
      "Epoch 2/50\n",
      "873/873 [==============================] - 397s 455ms/step - loss: 0.3514 - accuracy: 0.9129 - val_loss: 1.4079 - val_accuracy: 0.7298\n",
      "Epoch 3/50\n",
      "873/873 [==============================] - 397s 455ms/step - loss: 0.2789 - accuracy: 0.9299 - val_loss: 1.4252 - val_accuracy: 0.7416\n",
      "Epoch 4/50\n",
      "873/873 [==============================] - 397s 454ms/step - loss: 0.2350 - accuracy: 0.9402 - val_loss: 1.1662 - val_accuracy: 0.7853\n",
      "Epoch 5/50\n",
      "873/873 [==============================] - 397s 454ms/step - loss: 0.2100 - accuracy: 0.9448 - val_loss: 0.8312 - val_accuracy: 0.8492\n",
      "Epoch 6/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.1948 - accuracy: 0.9498 - val_loss: 1.0690 - val_accuracy: 0.8023\n",
      "Epoch 7/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.1626 - accuracy: 0.9575 - val_loss: 1.4807 - val_accuracy: 0.7535\n",
      "Epoch 8/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.1638 - accuracy: 0.9574 - val_loss: 1.1747 - val_accuracy: 0.8114\n",
      "Epoch 9/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.1413 - accuracy: 0.9630 - val_loss: 1.1964 - val_accuracy: 0.8147\n",
      "Epoch 10/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.1376 - accuracy: 0.9632 - val_loss: 1.3527 - val_accuracy: 0.8117\n",
      "Epoch 11/50\n",
      "873/873 [==============================] - 396s 453ms/step - loss: 0.1283 - accuracy: 0.9651 - val_loss: 1.1604 - val_accuracy: 0.8202\n",
      "Epoch 12/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.1146 - accuracy: 0.9693 - val_loss: 1.3934 - val_accuracy: 0.8358\n",
      "Epoch 13/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.1136 - accuracy: 0.9698 - val_loss: 1.3719 - val_accuracy: 0.8160\n",
      "Epoch 14/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.1072 - accuracy: 0.9718 - val_loss: 3.0737 - val_accuracy: 0.7284\n",
      "Epoch 15/50\n",
      "873/873 [==============================] - 398s 456ms/step - loss: 0.0986 - accuracy: 0.9731 - val_loss: 0.8042 - val_accuracy: 0.8827\n",
      "Epoch 16/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0998 - accuracy: 0.9734 - val_loss: 1.2633 - val_accuracy: 0.8420\n",
      "Epoch 17/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0895 - accuracy: 0.9754 - val_loss: 1.1318 - val_accuracy: 0.8692\n",
      "Epoch 18/50\n",
      "873/873 [==============================] - 396s 453ms/step - loss: 0.0926 - accuracy: 0.9751 - val_loss: 0.7055 - val_accuracy: 0.9013\n",
      "Epoch 19/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0842 - accuracy: 0.9771 - val_loss: 1.0735 - val_accuracy: 0.8410\n",
      "Epoch 20/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0832 - accuracy: 0.9775 - val_loss: 0.9632 - val_accuracy: 0.8640\n",
      "Epoch 21/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0753 - accuracy: 0.9792 - val_loss: 1.0605 - val_accuracy: 0.8594\n",
      "Epoch 22/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0761 - accuracy: 0.9800 - val_loss: 1.0377 - val_accuracy: 0.8658\n",
      "Epoch 23/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.0695 - accuracy: 0.9811 - val_loss: 1.5592 - val_accuracy: 0.8228\n",
      "Epoch 24/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0730 - accuracy: 0.9801 - val_loss: 0.9493 - val_accuracy: 0.8810\n",
      "Epoch 25/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.0710 - accuracy: 0.9807 - val_loss: 1.1260 - val_accuracy: 0.8719\n",
      "Epoch 26/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.0641 - accuracy: 0.9824 - val_loss: 1.1669 - val_accuracy: 0.8690\n",
      "Epoch 27/50\n",
      "873/873 [==============================] - 400s 459ms/step - loss: 0.0732 - accuracy: 0.9805 - val_loss: 1.0550 - val_accuracy: 0.8848\n",
      "Epoch 28/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0582 - accuracy: 0.9843 - val_loss: 1.6514 - val_accuracy: 0.8251\n",
      "Epoch 29/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0705 - accuracy: 0.9813 - val_loss: 1.3503 - val_accuracy: 0.8551\n",
      "Epoch 30/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0597 - accuracy: 0.9836 - val_loss: 1.3112 - val_accuracy: 0.8733\n",
      "Epoch 31/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0523 - accuracy: 0.9864 - val_loss: 1.2894 - val_accuracy: 0.8717\n",
      "Epoch 32/50\n",
      "873/873 [==============================] - 394s 452ms/step - loss: 0.0596 - accuracy: 0.9840 - val_loss: 1.5984 - val_accuracy: 0.8449\n",
      "Epoch 33/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0573 - accuracy: 0.9849 - val_loss: 1.3234 - val_accuracy: 0.8709\n",
      "Epoch 34/50\n",
      "873/873 [==============================] - 397s 455ms/step - loss: 0.0573 - accuracy: 0.9851 - val_loss: 1.2474 - val_accuracy: 0.8794\n",
      "Epoch 35/50\n",
      "873/873 [==============================] - 408s 467ms/step - loss: 0.0502 - accuracy: 0.9863 - val_loss: 1.2985 - val_accuracy: 0.8682\n",
      "Epoch 36/50\n",
      "873/873 [==============================] - 408s 468ms/step - loss: 0.0598 - accuracy: 0.9842 - val_loss: 1.0112 - val_accuracy: 0.8881\n",
      "Epoch 37/50\n",
      "873/873 [==============================] - 394s 452ms/step - loss: 0.0516 - accuracy: 0.9865 - val_loss: 0.9193 - val_accuracy: 0.8907\n",
      "Epoch 38/50\n",
      "873/873 [==============================] - 394s 452ms/step - loss: 0.0547 - accuracy: 0.9857 - val_loss: 1.1313 - val_accuracy: 0.8979\n",
      "Epoch 39/50\n",
      "873/873 [==============================] - 394s 452ms/step - loss: 0.0486 - accuracy: 0.9869 - val_loss: 1.2691 - val_accuracy: 0.8840\n",
      "Epoch 40/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0518 - accuracy: 0.9866 - val_loss: 1.2869 - val_accuracy: 0.8695\n",
      "Epoch 41/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0500 - accuracy: 0.9872 - val_loss: 1.1560 - val_accuracy: 0.8905\n",
      "Epoch 42/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0589 - accuracy: 0.9854 - val_loss: 1.0183 - val_accuracy: 0.8888\n",
      "Epoch 43/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0490 - accuracy: 0.9876 - val_loss: 1.4759 - val_accuracy: 0.8731\n",
      "Epoch 44/50\n",
      "873/873 [==============================] - 395s 452ms/step - loss: 0.0440 - accuracy: 0.9882 - val_loss: 2.0217 - val_accuracy: 0.8584\n",
      "Epoch 45/50\n",
      "873/873 [==============================] - 396s 453ms/step - loss: 0.0541 - accuracy: 0.9866 - val_loss: 1.1653 - val_accuracy: 0.8882\n",
      "Epoch 46/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.0448 - accuracy: 0.9880 - val_loss: 1.3033 - val_accuracy: 0.8906\n",
      "Epoch 47/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.0501 - accuracy: 0.9875 - val_loss: 1.4679 - val_accuracy: 0.8850\n",
      "Epoch 48/50\n",
      "873/873 [==============================] - 396s 454ms/step - loss: 0.0503 - accuracy: 0.9875 - val_loss: 1.1836 - val_accuracy: 0.9090\n",
      "Epoch 49/50\n",
      "873/873 [==============================] - 395s 453ms/step - loss: 0.0446 - accuracy: 0.9892 - val_loss: 1.7529 - val_accuracy: 0.8723\n",
      "Epoch 50/50\n",
      "873/873 [==============================] - 396s 453ms/step - loss: 0.0491 - accuracy: 0.9877 - val_loss: 1.4229 - val_accuracy: 0.8960\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=50, validation_data =(X_test, Y_test) , batch_size=64 , callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('checkpoint/MFKR_Model_Aug_pre_50epochs.hdf5')\n",
    "np.save('checkpoint/MFKR_Model_training_history_50epochs.npy', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 13s 105ms/step - loss: 1.4229 - accuracy: 0.8960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.422884464263916, 0.8959899544715881]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 13:28:15.521245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38541 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB MIG 3g.40gb, pci bus id: 0000:c2:00.0, compute capability: 8.0\n",
      "2023-06-29 13:28:23.733589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/63 [..............................] - ETA: 8:10 - loss: 0.1210 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 13:28:28.563166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 22s 221ms/step - loss: 1.1836 - accuracy: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1836411952972412, 0.9090225696563721]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "saved_model = load_model('checkpoint/checkpoint_pv5.h5')\n",
    "\n",
    "saved_model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('checkpoint/MFKR_Model_Aug_pre_50epochs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 16s 104ms/step - loss: 1.4229 - accuracy: 0.8960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.422884464263916, 0.8959899544715881]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 12:27:47.352857: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1201213440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 18s 61ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        42\n",
      "           1     1.0000    0.5952    0.7463        42\n",
      "           2     1.0000    1.0000    1.0000        42\n",
      "           3     1.0000    0.9048    0.9500        42\n",
      "           4     0.9333    1.0000    0.9655        42\n",
      "           5     0.9545    1.0000    0.9767        42\n",
      "           6     0.9545    1.0000    0.9767        42\n",
      "           7     0.9524    0.9524    0.9524        42\n",
      "           8     1.0000    1.0000    1.0000        42\n",
      "           9     1.0000    1.0000    1.0000        42\n",
      "          10     0.9767    1.0000    0.9882        42\n",
      "          11     0.7949    0.7381    0.7654        42\n",
      "          12     1.0000    0.9524    0.9756        42\n",
      "          13     0.8936    1.0000    0.9438        42\n",
      "          14     0.9767    1.0000    0.9882        42\n",
      "          15     1.0000    1.0000    1.0000        42\n",
      "          16     0.8235    1.0000    0.9032        42\n",
      "          17     1.0000    1.0000    1.0000        42\n",
      "          18     1.0000    0.9762    0.9880        42\n",
      "          19     0.5833    0.8333    0.6863        42\n",
      "          20     1.0000    1.0000    1.0000        42\n",
      "          21     1.0000    0.7857    0.8800        42\n",
      "          22     0.7368    1.0000    0.8485        42\n",
      "          23     1.0000    1.0000    1.0000        42\n",
      "          24     0.9487    0.8810    0.9136        42\n",
      "          25     1.0000    0.9524    0.9756        42\n",
      "          26     0.8077    1.0000    0.8936        42\n",
      "          27     1.0000    0.7619    0.8649        42\n",
      "          28     0.7925    1.0000    0.8842        42\n",
      "          29     1.0000    1.0000    1.0000        42\n",
      "          30     0.4884    1.0000    0.6562        42\n",
      "          31     0.7636    1.0000    0.8660        42\n",
      "          32     0.9767    1.0000    0.9882        42\n",
      "          33     0.9545    1.0000    0.9767        42\n",
      "          34     1.0000    1.0000    1.0000        42\n",
      "          35     0.8936    1.0000    0.9438        42\n",
      "          36     1.0000    1.0000    1.0000        42\n",
      "          37     0.9762    0.9762    0.9762        42\n",
      "          38     0.9130    1.0000    0.9545        42\n",
      "          39     1.0000    0.9762    0.9880        42\n",
      "          40     1.0000    1.0000    1.0000        42\n",
      "          41     0.8571    1.0000    0.9231        42\n",
      "          42     0.8750    1.0000    0.9333        42\n",
      "          43     0.9535    0.9762    0.9647        42\n",
      "          44     0.8077    1.0000    0.8936        42\n",
      "          45     1.0000    0.7143    0.8333        42\n",
      "          46     0.9545    1.0000    0.9767        42\n",
      "          47     1.0000    1.0000    1.0000        42\n",
      "          48     0.7500    1.0000    0.8571        42\n",
      "          49     0.9545    1.0000    0.9767        42\n",
      "          50     0.9302    0.9524    0.9412        42\n",
      "          51     0.8571    1.0000    0.9231        42\n",
      "          52     0.8750    1.0000    0.9333        42\n",
      "          53     0.4565    1.0000    0.6269        42\n",
      "          54     0.9767    1.0000    0.9882        42\n",
      "          55     1.0000    1.0000    1.0000        42\n",
      "          56     1.0000    0.9524    0.9756        42\n",
      "          57     1.0000    0.9762    0.9880        42\n",
      "          58     0.0256    0.0238    0.0247        42\n",
      "          59     0.9744    0.9048    0.9383        42\n",
      "          60     0.8936    1.0000    0.9438        42\n",
      "          61     0.7925    1.0000    0.8842        42\n",
      "          62     0.9286    0.3095    0.4643        42\n",
      "          63     1.0000    0.3095    0.4727        42\n",
      "          64     0.6393    0.9286    0.7573        42\n",
      "          65     0.9762    0.9762    0.9762        42\n",
      "          66     0.9583    0.5476    0.6970        42\n",
      "          67     0.9722    0.8333    0.8974        42\n",
      "          68     0.8936    1.0000    0.9438        42\n",
      "          69     0.9333    1.0000    0.9655        42\n",
      "          70     0.9333    1.0000    0.9655        42\n",
      "          71     0.9286    0.9286    0.9286        42\n",
      "          72     0.8077    1.0000    0.8936        42\n",
      "          73     0.7368    1.0000    0.8485        42\n",
      "          74     0.7636    1.0000    0.8660        42\n",
      "          75     0.7368    1.0000    0.8485        42\n",
      "          76     1.0000    0.9762    0.9880        42\n",
      "          77     0.4078    1.0000    0.5793        42\n",
      "          78     0.9130    1.0000    0.9545        42\n",
      "          79     0.9545    1.0000    0.9767        42\n",
      "          80     0.8400    1.0000    0.9130        42\n",
      "          81     0.9333    1.0000    0.9655        42\n",
      "          82     0.9545    1.0000    0.9767        42\n",
      "          83     0.9333    1.0000    0.9655        42\n",
      "          84     0.7241    1.0000    0.8400        42\n",
      "          85     1.0000    1.0000    1.0000        42\n",
      "          86     0.9767    1.0000    0.9882        42\n",
      "          87     0.8235    1.0000    0.9032        42\n",
      "          88     0.8400    1.0000    0.9130        42\n",
      "          89     1.0000    0.9048    0.9500        42\n",
      "          90     0.9130    1.0000    0.9545        42\n",
      "          91     1.0000    1.0000    1.0000        42\n",
      "          92     0.9333    1.0000    0.9655        42\n",
      "          93     0.9545    1.0000    0.9767        42\n",
      "          94     0.8367    0.9762    0.9011        42\n",
      "          95     1.0000    1.0000    1.0000        42\n",
      "          96     1.0000    1.0000    1.0000        42\n",
      "          97     0.8235    1.0000    0.9032        42\n",
      "          98     0.9130    1.0000    0.9545        42\n",
      "          99     0.9767    1.0000    0.9882        42\n",
      "         100     0.9512    0.9286    0.9398        42\n",
      "         101     0.6885    1.0000    0.8155        42\n",
      "         102     1.0000    1.0000    1.0000        42\n",
      "         103     0.8542    0.9762    0.9111        42\n",
      "         104     0.9545    1.0000    0.9767        42\n",
      "         105     1.0000    1.0000    1.0000        42\n",
      "         106     0.9767    1.0000    0.9882        42\n",
      "         107     0.9737    0.8810    0.9250        42\n",
      "         108     1.0000    1.0000    1.0000        42\n",
      "         109     1.0000    1.0000    1.0000        42\n",
      "         110     0.8913    0.9762    0.9318        42\n",
      "         111     1.0000    0.6905    0.8169        42\n",
      "         112     0.9487    0.8810    0.9136        42\n",
      "         113     1.0000    1.0000    1.0000        42\n",
      "         114     1.0000    1.0000    1.0000        42\n",
      "         115     0.9535    0.9762    0.9647        42\n",
      "         116     1.0000    0.3095    0.4727        42\n",
      "         117     1.0000    1.0000    1.0000        42\n",
      "         118     0.9545    1.0000    0.9767        42\n",
      "         119     1.0000    0.1190    0.2128        42\n",
      "         120     1.0000    0.8571    0.9231        42\n",
      "         121     0.9762    0.9762    0.9762        42\n",
      "         122     1.0000    1.0000    1.0000        42\n",
      "         123     1.0000    0.8095    0.8947        42\n",
      "         124     1.0000    1.0000    1.0000        42\n",
      "         125     1.0000    1.0000    1.0000        42\n",
      "         126     1.0000    0.6190    0.7647        42\n",
      "         127     1.0000    0.2381    0.3846        42\n",
      "         128     0.8571    1.0000    0.9231        42\n",
      "         129     0.9744    0.9048    0.9383        42\n",
      "         130     0.9167    0.7857    0.8462        42\n",
      "         131     1.0000    1.0000    1.0000        42\n",
      "         132     1.0000    1.0000    1.0000        42\n",
      "         133     0.9545    1.0000    0.9767        42\n",
      "         134     1.0000    1.0000    1.0000        42\n",
      "         135     0.9333    1.0000    0.9655        42\n",
      "         136     0.9111    0.9762    0.9425        42\n",
      "         137     0.9688    0.7381    0.8378        42\n",
      "         138     1.0000    0.9762    0.9880        42\n",
      "         139     0.9412    0.7619    0.8421        42\n",
      "         140     0.0000    0.0000    0.0000        42\n",
      "         141     1.0000    0.5000    0.6667        42\n",
      "         142     0.9767    1.0000    0.9882        42\n",
      "         143     1.0000    1.0000    1.0000        42\n",
      "         144     1.0000    0.8333    0.9091        42\n",
      "         145     0.9762    0.9762    0.9762        42\n",
      "         146     1.0000    1.0000    1.0000        42\n",
      "         147     1.0000    0.4048    0.5763        42\n",
      "         148     1.0000    0.8095    0.8947        42\n",
      "         149     1.0000    0.8095    0.8947        42\n",
      "         150     0.9130    1.0000    0.9545        42\n",
      "         151     1.0000    1.0000    1.0000        42\n",
      "         152     1.0000    1.0000    1.0000        42\n",
      "         153     0.9118    0.7381    0.8158        42\n",
      "         154     1.0000    0.9286    0.9630        42\n",
      "         155     0.9545    1.0000    0.9767        42\n",
      "         156     0.8936    1.0000    0.9438        42\n",
      "         157     1.0000    1.0000    1.0000        42\n",
      "         158     0.8750    1.0000    0.9333        42\n",
      "         159     1.0000    0.7619    0.8649        42\n",
      "         160     1.0000    0.8333    0.9091        42\n",
      "         161     0.6562    1.0000    0.7925        42\n",
      "         162     1.0000    0.9048    0.9500        42\n",
      "         163     1.0000    0.8333    0.9091        42\n",
      "         164     1.0000    0.8810    0.9367        42\n",
      "         165     0.8913    0.9762    0.9318        42\n",
      "         166     1.0000    0.2143    0.3529        42\n",
      "         167     1.0000    0.9048    0.9500        42\n",
      "         168     1.0000    0.8810    0.9367        42\n",
      "         169     0.9767    1.0000    0.9882        42\n",
      "         170     1.0000    0.8333    0.9091        42\n",
      "         171     0.9333    1.0000    0.9655        42\n",
      "         172     1.0000    0.8095    0.8947        42\n",
      "         173     0.8571    1.0000    0.9231        42\n",
      "         174     0.9762    0.9762    0.9762        42\n",
      "         175     1.0000    1.0000    1.0000        42\n",
      "         176     1.0000    1.0000    1.0000        42\n",
      "         177     0.9318    0.9762    0.9535        42\n",
      "         178     1.0000    0.7143    0.8333        42\n",
      "         179     0.9767    1.0000    0.9882        42\n",
      "         180     0.9091    0.4762    0.6250        42\n",
      "         181     1.0000    1.0000    1.0000        42\n",
      "         182     0.8936    1.0000    0.9438        42\n",
      "         183     1.0000    0.8333    0.9091        42\n",
      "         184     1.0000    1.0000    1.0000        42\n",
      "         185     1.0000    0.0714    0.1333        42\n",
      "         186     0.9318    0.9762    0.9535        42\n",
      "         187     0.9545    1.0000    0.9767        42\n",
      "         188     0.9767    1.0000    0.9882        42\n",
      "         189     0.8235    1.0000    0.9032        42\n",
      "\n",
      "    accuracy                         0.9090      7980\n",
      "   macro avg     0.9245    0.9090    0.8998      7980\n",
      "weighted avg     0.9245    0.9090    0.8998      7980\n",
      "\n",
      "[[42  0  0 ...  0  0  0]\n",
      " [ 0 25  0 ...  0  0  0]\n",
      " [ 0  0 42 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 42  0  0]\n",
      " [ 0  0  0 ...  0 42  0]\n",
      " [ 0  0  0 ...  0  0 42]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = saved_model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm= confusion_matrix(Y_test,y_pred)\n",
    "# np.set_printoptions(precision=2)\n",
    "cr = classification_report(Y_test, y_pred, digits=4)\n",
    "print(cr)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False discovery rate (FDR) of the model: 0.09097744360902256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# assume y_true is the true labels and y_pred is the predicted labels\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# calculate total false positives and true positives\n",
    "fp = np.sum(cm, axis=0) - np.diag(cm)\n",
    "tp = np.diag(cm)\n",
    "\n",
    "# calculate total false discovery rate\n",
    "fdr = np.sum(fp) / (np.sum(fp) + np.sum(tp))\n",
    "\n",
    "print(\"False discovery rate (FDR) of the model:\", fdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (TPR) of the model: 0.9090225563909774\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# assume y_true is the true labels and y_pred is the predicted labels\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# calculate total true positives and false negatives\n",
    "tp = np.diag(cm)\n",
    "fn = np.sum(cm, axis=1) - tp\n",
    "\n",
    "# calculate total sensitivity (TPR)\n",
    "sensitivity = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "\n",
    "print(\"Sensitivity (TPR) of the model:\", sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossover Error Rate (CER): 0.04572940287226\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# assume y_true is the true labels and y_pred is the predicted labels\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# calculate false positives (FP), false negatives (FN), true positives (TP), and true negatives (TN)\n",
    "FP = np.sum(cm, axis=0) - np.diag(cm)\n",
    "FN = np.sum(cm, axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = np.sum(cm) - (FP + FN + TP)\n",
    "\n",
    "# calculate the False Positive Rate (FPR) and False Negative Rate (FNR)\n",
    "FPR = FP / (FP + TN)\n",
    "FNR = FN / (FN + TP)\n",
    "\n",
    "# calculate the Crossover Error Rate (CER)\n",
    "CER = (FPR + FNR) / 2\n",
    "\n",
    "print(\"Crossover Error Rate (CER):\", np.mean(CER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive rate for the model: 0.00048136213549747385\n",
      "false negative rate for the model: 0.09097744360902256\n",
      "0.09097744360902256\n"
     ]
    }
   ],
   "source": [
    "FPR = np.sum(FP) / np.sum(FP + TN)\n",
    "FNR = np.sum(FN) / np.sum(FN + TP)\n",
    "FDR = np.sum(FP) / np.sum(FP + TP)\n",
    "\n",
    "print(\"false positive rate for the model:\", FPR)\n",
    "print(\"false negative rate for the model:\", FNR)\n",
    "print(FDR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
