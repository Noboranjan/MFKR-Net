{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 12:14:10.797791: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 12:14:11.561013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bigdata_user5/Desktop/envs/nobo/lib/\n",
      "2023-05-20 12:14:11.561089: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bigdata_user5/Desktop/envs/nobo/lib/\n",
      "2023-05-20 12:14:11.561095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-d456bb71-756c-5f6b-b13b-6793b90de8b7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7980\n",
      "7980\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "train_subject_types = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "input_images=[]\n",
    "input_labels=[]\n",
    "\n",
    "train_type = ['middlefinger']\n",
    "train_set=['set1','set2','set3','set4','set5','set6']\n",
    "\n",
    "def scan_folder(train_dataset_path,label):\n",
    "    images = []\n",
    "    labels=[]\n",
    "    complete_path=[x[0] for x in os.walk(train_dataset_path)]\n",
    "    for file_name in complete_path:\n",
    "        #print(file_name)\n",
    "        for fn in  os.listdir(file_name) :\n",
    "            # print(fn)\n",
    "            if fn.endswith(\".bmp\"):\n",
    "            # if it's a txt file, print its name (or do whatever you want)\n",
    "                # print(file_name)\n",
    "                #im = Image.open(file_name+'/'+fn)\n",
    "                im = cv2.imread(file_name+'/'+fn)\n",
    "                # im.show()\n",
    "                #img_arr=cv2.resize(im,(160,160))\n",
    "                img_arr=im \n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "                #print(im.size)\n",
    "                #print(im.filename)\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((train_dataset_path, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recursively call this method\n",
    "                scan_folder(current_path)\n",
    "    #print(images)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "for item1 in train_subject_types:\n",
    "    all_train_subjects = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down' + '/' +item1)\n",
    "    #print(all_subjects)\n",
    "    for item2 in train_type:\n",
    "        for item3 in train_set:\n",
    "            path=str('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down'  + '/' +item1 +  '/session1'+ '/' +item2 + '/'+item3+ '/3D')\n",
    "            img,label=scan_folder(path,item1)\n",
    "            input_images.extend(img)\n",
    "            input_labels.extend(label)\n",
    "            #print(input_labels)\n",
    "\n",
    "input_train_images=np.array(input_images)  \n",
    "input_train_labels=np.array(input_labels)\n",
    "print(len(input_train_images))\n",
    "print(len(input_train_labels))\n",
    "#print(input_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7980, 149, 212, 3)\n",
      "(7980,)\n",
      "7980\n",
      "7980\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "test_subject_types = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "input_images=[]\n",
    "input_labels=[]\n",
    "\n",
    "test_type = ['middlefinger']\n",
    "test_set=['set1','set2','set3','set4','set5','set6']\n",
    "\n",
    "\n",
    "def scan_folder(test_dataset_path,label):\n",
    "    images = []\n",
    "    labels=[]\n",
    "    #print(test_dataset_path)\n",
    "    complete_path=[x[0] for x in os.walk(test_dataset_path)]\n",
    "    #print(complete_path)\n",
    "    for file_name in complete_path:\n",
    "        #print(file_name)\n",
    "        for fn in  os.listdir(file_name) :\n",
    "            # print(fn)\n",
    "            if fn.endswith(\".bmp\"):\n",
    "            # if it's a txt file, print its name (or do whatever you want)\n",
    "                # print(file_name)\n",
    "                #im = Image.open(file_name+'/'+fn)\n",
    "                im = cv2.imread(file_name+'/'+fn)\n",
    "                # im.show()\n",
    "                img_arr=cv2.resize(im,(212,149))\n",
    "                #img_arr=im\n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((test_dataset_path, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recursively call this method\n",
    "                scan_folder(current_path)\n",
    "    #print(images)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "for item1 in train_subject_types:\n",
    "    #all_train_subjects = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down' + '/' +item1)\n",
    "    #print(all_train_subjects)\n",
    "    for item2 in test_type:\n",
    "        for item3 in test_set:\n",
    "            path=str('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down'  + '/' +item1 +  '/session2'+ '/' +item2 + '/'+item3+ '/3D')\n",
    "            img,label=scan_folder(path,item1)\n",
    "            input_images.extend(img)\n",
    "            input_labels.extend(label)\n",
    "            # print(input_labels)\n",
    "\n",
    "input_test_images=np.array(input_images) #,axis=0)\n",
    "input_test_labels=np.array(input_labels)\n",
    "# print(input_labels.shape)\n",
    "# input_test_labels=np.concatenate(np.array(input_labels),axis=0)\n",
    "print(input_test_images.shape)\n",
    "print(input_test_labels.shape)\n",
    "print(len(input_test_images))    \n",
    "print(len(input_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7980, 149, 212, 3)\n",
      "(7980,)\n",
      "(7980, 149, 212, 3)\n",
      "(7980,)\n"
     ]
    }
   ],
   "source": [
    "X_train = input_train_images\n",
    "Y_train = input_train_labels\n",
    "\n",
    "X_test = input_test_images\n",
    "Y_test = input_test_labels\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train/22.0\n",
    "# X_test = X_test/35.0\n",
    "\n",
    "# X_train[1,:]\n",
    "# X_test[1,:]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb= LabelEncoder()\n",
    "Y_train = lb.fit_transform(Y_train)\n",
    "Y_test = lb.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_2370236/3934639393.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 12:14:49.761050: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 12:14:50.304426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 38541 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB MIG 3g.40gb, pci bus id: 0000:c2:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 12:14:51.735929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38541 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB MIG 3g.40gb, pci bus id: 0000:c2:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "img_height,img_width = 149,212 \n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = tf.keras.applications.DenseNet121(weights=\"imagenet\", include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "predictions = Dense(190, activation= 'softmax')(x)\n",
    "model = tf.keras.Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 12:15:31.338371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-05-20 12:15:34.279975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-20 12:15:34.282403: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x4ae06270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-20 12:15:34.282435: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB MIG 3g.40gb, Compute Capability 8.0\n",
      "2023-05-20 12:15:34.287530: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-20 12:15:34.400317: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 76s 327ms/step - loss: 2.7716 - accuracy: 0.4504\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 293ms/step - loss: 0.0903 - accuracy: 0.9907\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 291ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 290ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 290ms/step - loss: 0.0041 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 7s 78ms/step - loss: 2.5812 - accuracy: 0.4752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5812292098999023, 0.4751879572868347]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/densenet121.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model/densenet_training_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 9s 27ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0476    0.0909        42\n",
      "           1     1.0000    0.0238    0.0465        42\n",
      "           2     0.3253    0.6429    0.4320        42\n",
      "           3     1.0000    0.3810    0.5517        42\n",
      "           4     0.5455    1.0000    0.7059        42\n",
      "           5     0.5753    1.0000    0.7304        42\n",
      "           6     0.8000    0.9524    0.8696        42\n",
      "           7     0.2143    0.4286    0.2857        42\n",
      "           8     0.8235    1.0000    0.9032        42\n",
      "           9     0.2718    0.6667    0.3862        42\n",
      "          10     0.8750    1.0000    0.9333        42\n",
      "          11     0.0741    0.0476    0.0580        42\n",
      "          12     0.0000    0.0000    0.0000        42\n",
      "          13     0.8667    0.9286    0.8966        42\n",
      "          14     0.4516    1.0000    0.6222        42\n",
      "          15     0.4200    1.0000    0.5915        42\n",
      "          16     0.7368    1.0000    0.8485        42\n",
      "          17     0.6774    1.0000    0.8077        42\n",
      "          18     0.3600    0.2143    0.2687        42\n",
      "          19     0.9070    0.9286    0.9176        42\n",
      "          20     0.3529    1.0000    0.5217        42\n",
      "          21     0.6607    0.8810    0.7551        42\n",
      "          22     0.3043    1.0000    0.4667        42\n",
      "          23     0.0000    0.0000    0.0000        42\n",
      "          24     0.7200    0.8571    0.7826        42\n",
      "          25     0.5775    0.9762    0.7257        42\n",
      "          26     0.2781    1.0000    0.4352        42\n",
      "          27     0.7407    0.9524    0.8333        42\n",
      "          28     0.6562    1.0000    0.7925        42\n",
      "          29     0.5143    0.8571    0.6429        42\n",
      "          30     0.3158    1.0000    0.4800        42\n",
      "          31     0.8235    1.0000    0.9032        42\n",
      "          32     0.4167    0.9524    0.5797        42\n",
      "          33     0.9545    1.0000    0.9767        42\n",
      "          34     0.0000    0.0000    0.0000        42\n",
      "          35     0.4127    0.6190    0.4952        42\n",
      "          36     0.8235    1.0000    0.9032        42\n",
      "          37     0.4286    1.0000    0.6000        42\n",
      "          38     0.6364    1.0000    0.7778        42\n",
      "          39     0.9318    0.9762    0.9535        42\n",
      "          40     0.3206    1.0000    0.4855        42\n",
      "          41     0.2857    0.5714    0.3810        42\n",
      "          42     0.5753    1.0000    0.7304        42\n",
      "          43     0.1410    0.2619    0.1833        42\n",
      "          44     0.2442    1.0000    0.3925        42\n",
      "          45     1.0000    0.2381    0.3846        42\n",
      "          46     0.7241    1.0000    0.8400        42\n",
      "          47     0.0000    0.0000    0.0000        42\n",
      "          48     0.3542    0.4048    0.3778        42\n",
      "          49     0.6176    1.0000    0.7636        42\n",
      "          50     0.3022    1.0000    0.4641        42\n",
      "          51     0.9545    1.0000    0.9767        42\n",
      "          52     0.4158    1.0000    0.5874        42\n",
      "          53     0.5060    1.0000    0.6720        42\n",
      "          54     0.5254    0.7381    0.6139        42\n",
      "          55     0.6667    1.0000    0.8000        42\n",
      "          56     0.9722    0.8333    0.8974        42\n",
      "          57     0.9211    0.8333    0.8750        42\n",
      "          58     0.1000    0.0238    0.0385        42\n",
      "          59     0.5714    0.4762    0.5195        42\n",
      "          60     0.0465    0.0476    0.0471        42\n",
      "          61     0.8182    0.2143    0.3396        42\n",
      "          62     0.0000    0.0000    0.0000        42\n",
      "          63     0.6667    0.0952    0.1667        42\n",
      "          64     0.2115    0.2619    0.2340        42\n",
      "          65     0.0000    0.0000    0.0000        42\n",
      "          66     0.4773    1.0000    0.6462        42\n",
      "          67     0.0000    0.0000    0.0000        42\n",
      "          68     0.3206    1.0000    0.4855        42\n",
      "          69     0.5455    1.0000    0.7059        42\n",
      "          70     0.6774    1.0000    0.8077        42\n",
      "          71     0.8750    1.0000    0.9333        42\n",
      "          72     0.4615    1.0000    0.6316        42\n",
      "          73     0.2917    1.0000    0.4516        42\n",
      "          74     1.0000    1.0000    1.0000        42\n",
      "          75     0.4421    1.0000    0.6131        42\n",
      "          76     0.9412    0.7619    0.8421        42\n",
      "          77     0.7321    0.9762    0.8367        42\n",
      "          78     0.0000    0.0000    0.0000        42\n",
      "          79     0.6774    1.0000    0.8077        42\n",
      "          80     0.6269    1.0000    0.7706        42\n",
      "          81     0.6269    1.0000    0.7706        42\n",
      "          82     0.7500    1.0000    0.8571        42\n",
      "          83     0.4286    1.0000    0.6000        42\n",
      "          84     0.4773    1.0000    0.6462        42\n",
      "          85     0.6087    1.0000    0.7568        42\n",
      "          86     0.6562    1.0000    0.7925        42\n",
      "          87     0.5676    1.0000    0.7241        42\n",
      "          88     0.5316    1.0000    0.6942        42\n",
      "          89     0.0000    0.0000    0.0000        42\n",
      "          90     0.5342    0.9286    0.6783        42\n",
      "          91     0.8235    1.0000    0.9032        42\n",
      "          92     0.3684    1.0000    0.5385        42\n",
      "          93     0.3043    1.0000    0.4667        42\n",
      "          94     0.4828    1.0000    0.6512        42\n",
      "          95     0.5970    0.9524    0.7339        42\n",
      "          96     0.3590    1.0000    0.5283        42\n",
      "          97     0.7500    1.0000    0.8571        42\n",
      "          98     0.8400    1.0000    0.9130        42\n",
      "          99     0.9762    0.9762    0.9762        42\n",
      "         100     1.0000    0.1190    0.2128        42\n",
      "         101     0.9545    1.0000    0.9767        42\n",
      "         102     0.2500    0.0238    0.0435        42\n",
      "         103     0.0000    0.0000    0.0000        42\n",
      "         104     1.0000    0.5952    0.7463        42\n",
      "         105     0.0000    0.0000    0.0000        42\n",
      "         106     0.0000    0.0000    0.0000        42\n",
      "         107     0.0000    0.0000    0.0000        42\n",
      "         108     0.0000    0.0000    0.0000        42\n",
      "         109     0.0000    0.0000    0.0000        42\n",
      "         110     0.0000    0.0000    0.0000        42\n",
      "         111     0.0000    0.0000    0.0000        42\n",
      "         112     0.4158    1.0000    0.5874        42\n",
      "         113     1.0000    0.2857    0.4444        42\n",
      "         114     0.0000    0.0000    0.0000        42\n",
      "         115     0.0000    0.0000    0.0000        42\n",
      "         116     0.0000    0.0000    0.0000        42\n",
      "         117     0.9730    0.8571    0.9114        42\n",
      "         118     1.0000    0.1190    0.2128        42\n",
      "         119     0.0000    0.0000    0.0000        42\n",
      "         120     0.7500    0.1429    0.2400        42\n",
      "         121     0.0000    0.0000    0.0000        42\n",
      "         122     0.0000    0.0000    0.0000        42\n",
      "         123     0.0000    0.0000    0.0000        42\n",
      "         124     1.0000    0.0476    0.0909        42\n",
      "         125     1.0000    0.0238    0.0465        42\n",
      "         126     0.9545    0.5000    0.6562        42\n",
      "         127     0.0000    0.0000    0.0000        42\n",
      "         128     0.0000    0.0000    0.0000        42\n",
      "         129     0.0000    0.0000    0.0000        42\n",
      "         130     0.8333    0.2381    0.3704        42\n",
      "         131     1.0000    0.4524    0.6230        42\n",
      "         132     0.0000    0.0000    0.0000        42\n",
      "         133     0.0000    0.0000    0.0000        42\n",
      "         134     0.7778    0.1667    0.2745        42\n",
      "         135     0.0000    0.0000    0.0000        42\n",
      "         136     1.0000    0.4524    0.6230        42\n",
      "         137     0.0000    0.0000    0.0000        42\n",
      "         138     0.0000    0.0000    0.0000        42\n",
      "         139     0.0000    0.0000    0.0000        42\n",
      "         140     0.0000    0.0000    0.0000        42\n",
      "         141     0.0000    0.0000    0.0000        42\n",
      "         142     0.4000    0.0952    0.1538        42\n",
      "         143     0.0000    0.0000    0.0000        42\n",
      "         144     0.0000    0.0000    0.0000        42\n",
      "         145     0.3333    0.1667    0.2222        42\n",
      "         146     0.0000    0.0000    0.0000        42\n",
      "         147     1.0000    0.0952    0.1739        42\n",
      "         148     1.0000    0.1905    0.3200        42\n",
      "         149     0.1000    0.0238    0.0385        42\n",
      "         150     0.8788    0.6905    0.7733        42\n",
      "         151     0.6429    0.2143    0.3214        42\n",
      "         152     1.0000    0.0238    0.0465        42\n",
      "         153     0.0000    0.0000    0.0000        42\n",
      "         154     0.0000    0.0000    0.0000        42\n",
      "         155     0.6429    0.2143    0.3214        42\n",
      "         156     0.1429    0.0238    0.0408        42\n",
      "         157     0.4000    0.0952    0.1538        42\n",
      "         158     0.0000    0.0000    0.0000        42\n",
      "         159     0.0000    0.0000    0.0000        42\n",
      "         160     1.0000    0.0952    0.1739        42\n",
      "         161     0.0000    0.0000    0.0000        42\n",
      "         162     1.0000    0.0238    0.0465        42\n",
      "         163     0.8750    0.1667    0.2800        42\n",
      "         164     0.0000    0.0000    0.0000        42\n",
      "         165     0.0000    0.0000    0.0000        42\n",
      "         166     0.0000    0.0000    0.0000        42\n",
      "         167     0.6000    0.0714    0.1277        42\n",
      "         168     0.0000    0.0000    0.0000        42\n",
      "         169     0.8750    0.1667    0.2800        42\n",
      "         170     0.1837    0.2143    0.1978        42\n",
      "         171     1.0000    0.1429    0.2500        42\n",
      "         172     0.0000    0.0000    0.0000        42\n",
      "         173     1.0000    0.7381    0.8493        42\n",
      "         174     0.5625    0.2143    0.3103        42\n",
      "         175     0.0000    0.0000    0.0000        42\n",
      "         176     0.6000    0.2857    0.3871        42\n",
      "         177     0.9302    0.9524    0.9412        42\n",
      "         178     0.0000    0.0000    0.0000        42\n",
      "         179     0.0000    0.0000    0.0000        42\n",
      "         180     0.0000    0.0000    0.0000        42\n",
      "         181     0.7576    0.5952    0.6667        42\n",
      "         182     0.0000    0.0000    0.0000        42\n",
      "         183     0.0000    0.0000    0.0000        42\n",
      "         184     0.0000    0.0000    0.0000        42\n",
      "         185     0.0000    0.0000    0.0000        42\n",
      "         186     0.0000    0.0000    0.0000        42\n",
      "         187     0.1963    1.0000    0.3281        42\n",
      "         188     0.4268    0.8333    0.5645        42\n",
      "         189     0.3256    1.0000    0.4912        42\n",
      "\n",
      "    accuracy                         0.4752      7980\n",
      "   macro avg     0.4418    0.4752    0.3867      7980\n",
      "weighted avg     0.4418    0.4752    0.3867      7980\n",
      "\n",
      "[[ 2  0  0 ...  0  0  0]\n",
      " [ 0  1 17 ...  0  0  0]\n",
      " [ 0  0 27 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 42  0  0]\n",
      " [ 0  0  0 ...  0 35  0]\n",
      " [ 0  0  0 ...  0  0 42]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm= confusion_matrix(Y_test,y_pred)\n",
    "# np.set_printoptions(precision=2)\n",
    "cr = classification_report(Y_test, y_pred, digits=4)\n",
    "print(cr)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (TPR) of the model: 0.47518796992481205\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# assume y_true is the true labels and y_pred is the predicted labels\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# calculate total true positives and false negatives\n",
    "tp = np.diag(cm)\n",
    "fn = np.sum(cm, axis=1) - tp\n",
    "\n",
    "# calculate total sensitivity (TPR)\n",
    "sensitivity = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "\n",
    "print(\"Sensitivity (TPR) of the model:\", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossover Error Rate (CER): 0.26379440665154946\n",
      "false positive rate for the model: 0.0027767832279110474\n",
      "false negative rate for the model: 0.524812030075188\n",
      "0.524812030075188\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# assume y_true is the true labels and y_pred is the predicted labels\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# calculate false positives (FP), false negatives (FN), true positives (TP), and true negatives (TN)\n",
    "FP = np.sum(cm, axis=0) - np.diag(cm)\n",
    "FN = np.sum(cm, axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = np.sum(cm) - (FP + FN + TP)\n",
    "\n",
    "# calculate the False Positive Rate (FPR) and False Negative Rate (FNR)\n",
    "FPR = FP / (FP + TN)\n",
    "FNR = FN / (FN + TP)\n",
    "\n",
    "# calculate the Crossover Error Rate (CER)\n",
    "CER = (FPR + FNR) / 2\n",
    "\n",
    "print(\"Crossover Error Rate (CER):\", np.mean(CER))\n",
    "\n",
    "FPR = np.sum(FP) / np.sum(FP + TN)\n",
    "FNR = np.sum(FN) / np.sum(FN + TP)\n",
    "FDR = np.sum(FP) / np.sum(FP + TP)\n",
    "\n",
    "print(\"false positive rate for the model:\", FPR)\n",
    "print(\"false negative rate for the model:\", FNR)\n",
    "print(FDR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b2f3040836d8930dd440357ce9e4d88224c51c61d44d8fa72c07609a2b5249b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
