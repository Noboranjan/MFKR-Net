{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 21:25:22.909588: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 21:25:23.601398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bigdata_user5/Desktop/envs/nobo/lib/\n",
      "2023-05-20 21:25:23.601467: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bigdata_user5/Desktop/envs/nobo/lib/\n",
      "2023-05-20 21:25:23.601473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-d456bb71-756c-5f6b-b13b-6793b90de8b7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7980\n",
      "7980\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "train_subject_types = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "input_images=[]\n",
    "input_labels=[]\n",
    "\n",
    "train_type = ['middlefinger']\n",
    "train_set=['set1','set2','set3','set4','set5','set6']\n",
    "\n",
    "def scan_folder(train_dataset_path,label):\n",
    "    images = []\n",
    "    labels=[]\n",
    "    complete_path=[x[0] for x in os.walk(train_dataset_path)]\n",
    "    for file_name in complete_path:\n",
    "        #print(file_name)\n",
    "        for fn in  os.listdir(file_name) :\n",
    "            # print(fn)\n",
    "            if fn.endswith(\".bmp\"):\n",
    "            # if it's a txt file, print its name (or do whatever you want)\n",
    "                # print(file_name)\n",
    "                #im = Image.open(file_name+'/'+fn)\n",
    "                im = cv2.imread(file_name+'/'+fn)\n",
    "                # im.show()\n",
    "                #img_arr=cv2.resize(im,(160,160))\n",
    "                img_arr=im \n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "                #print(im.size)\n",
    "                #print(im.filename)\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((train_dataset_path, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recursively call this method\n",
    "                scan_folder(current_path)\n",
    "    #print(images)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "for item1 in train_subject_types:\n",
    "    all_train_subjects = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down' + '/' +item1)\n",
    "    #print(all_subjects)\n",
    "    for item2 in train_type:\n",
    "        for item3 in train_set:\n",
    "            path=str('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down'  + '/' +item1 +  '/session1'+ '/' +item2 + '/'+item3+ '/3D')\n",
    "            img,label=scan_folder(path,item1)\n",
    "            input_images.extend(img)\n",
    "            input_labels.extend(label)\n",
    "            #print(input_labels)\n",
    "\n",
    "input_train_images=np.array(input_images)  \n",
    "input_train_labels=np.array(input_labels)\n",
    "print(len(input_train_images))\n",
    "print(len(input_train_labels))\n",
    "#print(input_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7980, 149, 212, 3)\n",
      "(7980,)\n",
      "7980\n",
      "7980\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "test_subject_types = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down')\n",
    "\n",
    "input_images=[]\n",
    "input_labels=[]\n",
    "\n",
    "test_type = ['middlefinger']\n",
    "test_set=['set1','set2','set3','set4','set5','set6']\n",
    "\n",
    "\n",
    "def scan_folder(test_dataset_path,label):\n",
    "    images = []\n",
    "    labels=[]\n",
    "    #print(test_dataset_path)\n",
    "    complete_path=[x[0] for x in os.walk(test_dataset_path)]\n",
    "    #print(complete_path)\n",
    "    for file_name in complete_path:\n",
    "        #print(file_name)\n",
    "        for fn in  os.listdir(file_name) :\n",
    "            # print(fn)\n",
    "            if fn.endswith(\".bmp\"):\n",
    "            # if it's a txt file, print its name (or do whatever you want)\n",
    "                # print(file_name)\n",
    "                #im = Image.open(file_name+'/'+fn)\n",
    "                im = cv2.imread(file_name+'/'+fn)\n",
    "                # im.show()\n",
    "                img_arr=cv2.resize(im,(212,149))\n",
    "                #img_arr=im\n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            current_path = \"\".join((test_dataset_path, \"/\", file_name))\n",
    "            if os.path.isdir(current_path):\n",
    "                # if we're checking a sub-directory, recursively call this method\n",
    "                scan_folder(current_path)\n",
    "    #print(images)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "for item1 in train_subject_types:\n",
    "    #all_train_subjects = os.listdir('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down' + '/' +item1)\n",
    "    #print(all_train_subjects)\n",
    "    for item2 in test_type:\n",
    "        for item3 in test_set:\n",
    "            path=str('data/3Dfingerknuckle/3D_Finger_Knuckle_Database/segmented_data_down'  + '/' +item1 +  '/session2'+ '/' +item2 + '/'+item3+ '/3D')\n",
    "            img,label=scan_folder(path,item1)\n",
    "            input_images.extend(img)\n",
    "            input_labels.extend(label)\n",
    "            # print(input_labels)\n",
    "\n",
    "input_test_images=np.array(input_images) #,axis=0)\n",
    "input_test_labels=np.array(input_labels)\n",
    "# print(input_labels.shape)\n",
    "# input_test_labels=np.concatenate(np.array(input_labels),axis=0)\n",
    "print(input_test_images.shape)\n",
    "print(input_test_labels.shape)\n",
    "print(len(input_test_images))    \n",
    "print(len(input_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7980, 149, 212, 3)\n",
      "(7980,)\n",
      "(7980, 149, 212, 3)\n",
      "(7980,)\n"
     ]
    }
   ],
   "source": [
    "X_train = input_train_images\n",
    "Y_train = input_train_labels\n",
    "\n",
    "X_test = input_test_images\n",
    "Y_test = input_test_labels\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train/22.0\n",
    "# X_test = X_test/35.0\n",
    "\n",
    "# X_train[1,:]\n",
    "# X_test[1,:]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb= LabelEncoder()\n",
    "Y_train = lb.fit_transform(Y_train)\n",
    "Y_test = lb.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_3917120/3934639393.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 21:25:43.105949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 21:25:43.714719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 38541 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB MIG 3g.40gb, pci bus id: 0000:c2:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "img_height,img_width = 149,212 \n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = tf.keras.applications.InceptionV3(weights=\"imagenet\", include_top=False, input_shape= (img_height,img_width,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "predictions = Dense(190, activation= 'softmax')(x)\n",
    "model = tf.keras.Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 21:26:10.382540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-05-20 21:26:12.941245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-20 21:26:12.943309: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f3f23901e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-20 21:26:12.943327: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB MIG 3g.40gb, Compute Capability 8.0\n",
      "2023-05-20 21:26:12.948030: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-20 21:26:13.059329: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 42s 178ms/step - loss: 5.0556 - accuracy: 0.0236\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 2.1133 - accuracy: 0.5099\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 9s 149ms/step - loss: 0.1782 - accuracy: 0.9524\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 9s 151ms/step - loss: 0.0276 - accuracy: 0.9939\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 0.0408 - accuracy: 0.9911\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 0.0475 - accuracy: 0.9878\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 0.0432 - accuracy: 0.9904\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 0.0208 - accuracy: 0.9956\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 9s 149ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 9s 151ms/step - loss: 5.4099e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 3.0369e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 9s 149ms/step - loss: 2.2886e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 9s 149ms/step - loss: 1.8454e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 1.4839e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 1.4546e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 9s 148ms/step - loss: 1.4003e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 9s 149ms/step - loss: 1.5641e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 1.1943e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 9.4914e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 10s 152ms/step - loss: 1.0055e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 4s 43ms/step - loss: 2.7610 - accuracy: 0.5612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7610387802124023, 0.5611528754234314]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/Inceptionv3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model/Inceptionv3_training_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 6s 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7619    0.8649        42\n",
      "           1     0.0000    0.0000    0.0000        42\n",
      "           2     0.1136    0.1190    0.1163        42\n",
      "           3     1.0000    0.4524    0.6230        42\n",
      "           4     0.8936    1.0000    0.9438        42\n",
      "           5     0.3500    1.0000    0.5185        42\n",
      "           6     0.5385    1.0000    0.7000        42\n",
      "           7     0.0175    0.0238    0.0202        42\n",
      "           8     0.4242    1.0000    0.5957        42\n",
      "           9     0.4737    0.8571    0.6102        42\n",
      "          10     0.8039    0.9762    0.8817        42\n",
      "          11     0.7692    0.2381    0.3636        42\n",
      "          12     0.0000    0.0000    0.0000        42\n",
      "          13     0.8605    0.8810    0.8706        42\n",
      "          14     0.4815    0.9286    0.6341        42\n",
      "          15     0.7241    1.0000    0.8400        42\n",
      "          16     0.9545    1.0000    0.9767        42\n",
      "          17     0.9545    1.0000    0.9767        42\n",
      "          18     0.1280    0.3810    0.1916        42\n",
      "          19     0.8500    0.8095    0.8293        42\n",
      "          20     0.5122    1.0000    0.6774        42\n",
      "          21     0.3364    0.8571    0.4832        42\n",
      "          22     0.3111    1.0000    0.4746        42\n",
      "          23     0.0000    0.0000    0.0000        42\n",
      "          24     0.5106    0.5714    0.5393        42\n",
      "          25     0.7321    0.9762    0.8367        42\n",
      "          26     0.9756    0.9524    0.9639        42\n",
      "          27     0.6000    0.9286    0.7290        42\n",
      "          28     0.8077    1.0000    0.8936        42\n",
      "          29     0.5676    1.0000    0.7241        42\n",
      "          30     0.3415    1.0000    0.5091        42\n",
      "          31     0.9130    1.0000    0.9545        42\n",
      "          32     0.5507    0.9048    0.6847        42\n",
      "          33     0.7925    1.0000    0.8842        42\n",
      "          34     1.0000    0.4286    0.6000        42\n",
      "          35     0.3434    0.8095    0.4823        42\n",
      "          36     0.7000    1.0000    0.8235        42\n",
      "          37     0.6364    1.0000    0.7778        42\n",
      "          38     0.3471    1.0000    0.5153        42\n",
      "          39     0.9302    0.9524    0.9412        42\n",
      "          40     0.7925    1.0000    0.8842        42\n",
      "          41     0.2293    0.8571    0.3618        42\n",
      "          42     0.9333    1.0000    0.9655        42\n",
      "          43     0.5185    0.6667    0.5833        42\n",
      "          44     0.2917    1.0000    0.4516        42\n",
      "          45     0.0000    0.0000    0.0000        42\n",
      "          46     0.8936    1.0000    0.9438        42\n",
      "          47     0.2500    0.1905    0.2162        42\n",
      "          48     0.2908    0.9762    0.4481        42\n",
      "          49     0.6176    1.0000    0.7636        42\n",
      "          50     1.0000    0.9286    0.9630        42\n",
      "          51     0.7778    1.0000    0.8750        42\n",
      "          52     0.9130    1.0000    0.9545        42\n",
      "          53     0.6441    0.9048    0.7525        42\n",
      "          54     0.3256    1.0000    0.4912        42\n",
      "          55     0.4375    1.0000    0.6087        42\n",
      "          56     0.0000    0.0000    0.0000        42\n",
      "          57     0.5325    0.9762    0.6891        42\n",
      "          58     0.0000    0.0000    0.0000        42\n",
      "          59     0.1034    0.0714    0.0845        42\n",
      "          60     0.0000    0.0000    0.0000        42\n",
      "          61     0.6471    0.7857    0.7097        42\n",
      "          62     0.0492    0.0714    0.0583        42\n",
      "          63     0.3684    0.1667    0.2295        42\n",
      "          64     1.0000    0.0476    0.0909        42\n",
      "          65     1.0000    0.0476    0.0909        42\n",
      "          66     0.3973    0.6905    0.5043        42\n",
      "          67     1.0000    0.0238    0.0465        42\n",
      "          68     0.7193    0.9762    0.8283        42\n",
      "          69     0.4857    0.8095    0.6071        42\n",
      "          70     0.6000    1.0000    0.7500        42\n",
      "          71     0.8750    1.0000    0.9333        42\n",
      "          72     0.9545    1.0000    0.9767        42\n",
      "          73     0.9130    1.0000    0.9545        42\n",
      "          74     1.0000    0.9048    0.9500        42\n",
      "          75     0.6269    1.0000    0.7706        42\n",
      "          76     1.0000    0.5952    0.7463        42\n",
      "          77     0.9767    1.0000    0.9882        42\n",
      "          78     0.0000    0.0000    0.0000        42\n",
      "          79     0.4615    1.0000    0.6316        42\n",
      "          80     0.9767    1.0000    0.9882        42\n",
      "          81     0.4200    1.0000    0.5915        42\n",
      "          82     0.7241    1.0000    0.8400        42\n",
      "          83     0.7000    1.0000    0.8235        42\n",
      "          84     0.4762    0.9524    0.6349        42\n",
      "          85     0.9130    1.0000    0.9545        42\n",
      "          86     0.4615    1.0000    0.6316        42\n",
      "          87     0.9767    1.0000    0.9882        42\n",
      "          88     0.6176    1.0000    0.7636        42\n",
      "          89     0.0000    0.0000    0.0000        42\n",
      "          90     0.5179    0.6905    0.5918        42\n",
      "          91     1.0000    1.0000    1.0000        42\n",
      "          92     0.5821    0.9286    0.7156        42\n",
      "          93     0.4938    0.9524    0.6504        42\n",
      "          94     0.5250    1.0000    0.6885        42\n",
      "          95     0.4286    0.2143    0.2857        42\n",
      "          96     0.3182    1.0000    0.4828        42\n",
      "          97     0.7636    1.0000    0.8660        42\n",
      "          98     0.7636    1.0000    0.8660        42\n",
      "          99     0.6029    0.9762    0.7455        42\n",
      "         100     1.0000    0.4048    0.5763        42\n",
      "         101     0.9767    1.0000    0.9882        42\n",
      "         102     1.0000    0.0952    0.1739        42\n",
      "         103     0.0000    0.0000    0.0000        42\n",
      "         104     0.0000    0.0000    0.0000        42\n",
      "         105     0.0000    0.0000    0.0000        42\n",
      "         106     1.0000    0.2857    0.4444        42\n",
      "         107     0.0000    0.0000    0.0000        42\n",
      "         108     0.5556    0.5952    0.5747        42\n",
      "         109     1.0000    0.5714    0.7273        42\n",
      "         110     0.0000    0.0000    0.0000        42\n",
      "         111     0.0000    0.0000    0.0000        42\n",
      "         112     0.9545    1.0000    0.9767        42\n",
      "         113     1.0000    1.0000    1.0000        42\n",
      "         114     0.2857    0.0476    0.0816        42\n",
      "         115     0.9444    0.4048    0.5667        42\n",
      "         116     0.0000    0.0000    0.0000        42\n",
      "         117     0.6364    1.0000    0.7778        42\n",
      "         118     0.6833    0.9762    0.8039        42\n",
      "         119     0.0000    0.0000    0.0000        42\n",
      "         120     0.0000    0.0000    0.0000        42\n",
      "         121     1.0000    0.0714    0.1333        42\n",
      "         122     1.0000    0.0476    0.0909        42\n",
      "         123     0.0000    0.0000    0.0000        42\n",
      "         124     1.0000    0.0238    0.0465        42\n",
      "         125     0.9259    0.5952    0.7246        42\n",
      "         126     0.0000    0.0000    0.0000        42\n",
      "         127     1.0000    0.0476    0.0909        42\n",
      "         128     0.0000    0.0000    0.0000        42\n",
      "         129     0.0000    0.0000    0.0000        42\n",
      "         130     0.8750    0.6667    0.7568        42\n",
      "         131     0.9286    0.9286    0.9286        42\n",
      "         132     0.0000    0.0000    0.0000        42\n",
      "         133     0.9524    0.4762    0.6349        42\n",
      "         134     1.0000    0.2143    0.3529        42\n",
      "         135     0.0000    0.0000    0.0000        42\n",
      "         136     1.0000    0.5714    0.7273        42\n",
      "         137     0.3333    0.0714    0.1176        42\n",
      "         138     0.0000    0.0000    0.0000        42\n",
      "         139     0.3529    0.1429    0.2034        42\n",
      "         140     0.0000    0.0000    0.0000        42\n",
      "         141     0.0000    0.0000    0.0000        42\n",
      "         142     0.0000    0.0000    0.0000        42\n",
      "         143     0.6667    0.0476    0.0889        42\n",
      "         144     0.4426    0.6429    0.5243        42\n",
      "         145     0.5636    0.7381    0.6392        42\n",
      "         146     0.0000    0.0000    0.0000        42\n",
      "         147     0.7500    0.0714    0.1304        42\n",
      "         148     0.7018    0.9524    0.8081        42\n",
      "         149     0.0000    0.0000    0.0000        42\n",
      "         150     1.0000    0.9048    0.9500        42\n",
      "         151     0.7000    1.0000    0.8235        42\n",
      "         152     0.0000    0.0000    0.0000        42\n",
      "         153     0.0000    0.0000    0.0000        42\n",
      "         154     0.1176    0.0476    0.0678        42\n",
      "         155     0.9655    0.6667    0.7887        42\n",
      "         156     0.9000    0.8571    0.8780        42\n",
      "         157     0.5556    0.1190    0.1961        42\n",
      "         158     0.0000    0.0000    0.0000        42\n",
      "         159     0.5862    0.4048    0.4789        42\n",
      "         160     0.5862    0.8095    0.6800        42\n",
      "         161     0.0000    0.0000    0.0000        42\n",
      "         162     1.0000    0.3095    0.4727        42\n",
      "         163     0.8140    0.8333    0.8235        42\n",
      "         164     0.0000    0.0000    0.0000        42\n",
      "         165     0.7778    0.1667    0.2745        42\n",
      "         166     0.0000    0.0000    0.0000        42\n",
      "         167     0.0000    0.0000    0.0000        42\n",
      "         168     0.0000    0.0000    0.0000        42\n",
      "         169     0.6500    0.6190    0.6341        42\n",
      "         170     0.8000    0.0952    0.1702        42\n",
      "         171     0.9048    0.9048    0.9048        42\n",
      "         172     0.9231    0.2857    0.4364        42\n",
      "         173     1.0000    0.9762    0.9880        42\n",
      "         174     0.5000    0.1190    0.1923        42\n",
      "         175     0.9091    0.4762    0.6250        42\n",
      "         176     0.7838    0.6905    0.7342        42\n",
      "         177     0.9000    0.8571    0.8780        42\n",
      "         178     0.9677    0.7143    0.8219        42\n",
      "         179     0.0000    0.0000    0.0000        42\n",
      "         180     0.5536    0.7381    0.6327        42\n",
      "         181     1.0000    0.9286    0.9630        42\n",
      "         182     1.0000    0.2619    0.4151        42\n",
      "         183     0.5000    0.0238    0.0455        42\n",
      "         184     1.0000    0.7857    0.8800        42\n",
      "         185     0.3571    0.1190    0.1786        42\n",
      "         186     0.0000    0.0000    0.0000        42\n",
      "         187     0.2386    1.0000    0.3853        42\n",
      "         188     0.3387    1.0000    0.5060        42\n",
      "         189     0.4000    1.0000    0.5714        42\n",
      "\n",
      "    accuracy                         0.5612      7980\n",
      "   macro avg     0.5442    0.5612    0.4903      7980\n",
      "weighted avg     0.5442    0.5612    0.4903      7980\n",
      "\n",
      "[[32  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  1  0  0]\n",
      " [ 0  0  5 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 42  0  0]\n",
      " [ 0  0  0 ...  0 42  0]\n",
      " [ 0  0  0 ...  0  0 42]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bigdata_user5/Desktop/envs/nobo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm= confusion_matrix(Y_test,y_pred)\n",
    "# np.set_printoptions(precision=2)\n",
    "cr = classification_report(Y_test, y_pred, digits=4)\n",
    "print(cr)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (TPR) of the model: 0.5611528822055137\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# assume y_true is the true labels and y_pred is the predicted labels\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# calculate total true positives and false negatives\n",
    "tp = np.diag(cm)\n",
    "fn = np.sum(cm, axis=1) - tp\n",
    "\n",
    "# calculate total sensitivity (TPR)\n",
    "sensitivity = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "\n",
    "print(\"Sensitivity (TPR) of the model:\", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossover Error Rate (CER): 0.22058453010833964\n",
      "false positive rate for the model: 0.0023219424221930488\n",
      "false negative rate for the model: 0.4388471177944862\n",
      "0.4388471177944862\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# assume y_true is the true labels and y_pred is the predicted labels\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# calculate false positives (FP), false negatives (FN), true positives (TP), and true negatives (TN)\n",
    "FP = np.sum(cm, axis=0) - np.diag(cm)\n",
    "FN = np.sum(cm, axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = np.sum(cm) - (FP + FN + TP)\n",
    "\n",
    "# calculate the False Positive Rate (FPR) and False Negative Rate (FNR)\n",
    "FPR = FP / (FP + TN)\n",
    "FNR = FN / (FN + TP)\n",
    "\n",
    "# calculate the Crossover Error Rate (CER)\n",
    "CER = (FPR + FNR) / 2\n",
    "\n",
    "print(\"Crossover Error Rate (CER):\", np.mean(CER))\n",
    "\n",
    "FPR = np.sum(FP) / np.sum(FP + TN)\n",
    "FNR = np.sum(FN) / np.sum(FN + TP)\n",
    "FDR = np.sum(FP) / np.sum(FP + TP)\n",
    "\n",
    "print(\"false positive rate for the model:\", FPR)\n",
    "print(\"false negative rate for the model:\", FNR)\n",
    "print(FDR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b2f3040836d8930dd440357ce9e4d88224c51c61d44d8fa72c07609a2b5249b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
